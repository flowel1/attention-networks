{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc6fcf7d0a4245c2aa894ee5c387f1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1c5fdbb56844cf2bb99e4efc4f0271e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1376e2d53ef5407c91900730a1ddf379",
              "IPY_MODEL_206d6ed9603f4c61add8cf13c16daabe"
            ]
          }
        },
        "b1c5fdbb56844cf2bb99e4efc4f0271e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1376e2d53ef5407c91900730a1ddf379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81317578f9664e50a9ed74b2e009f26b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8e26c1c25d24407bbee27cf090bba1d"
          }
        },
        "206d6ed9603f4c61add8cf13c16daabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e23bd30c1a93418889ed0c318f993d05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 17.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ad4a839b38e4b258dce1d039e2a1cf9"
          }
        },
        "81317578f9664e50a9ed74b2e009f26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8e26c1c25d24407bbee27cf090bba1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e23bd30c1a93418889ed0c318f993d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ad4a839b38e4b258dce1d039e2a1cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b013cfeb128d46c8b601fbcfb7d4d872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1863fbf56e81423cafb200e250f22504",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5133554687241beb4a14ba5a8a48e65",
              "IPY_MODEL_81c681f999c3480cba9383256edd8fa2"
            ]
          }
        },
        "1863fbf56e81423cafb200e250f22504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5133554687241beb4a14ba5a8a48e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3532353a7ae246f0a266b42d38cc4901",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1083389348,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1083389348,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8555ca1f86bf4ab5bf01e76d8d17ba60"
          }
        },
        "81c681f999c3480cba9383256edd8fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a3f5d1ddcea4cc08ff77ad0b333ea38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1.08G/1.08G [00:16&lt;00:00, 66.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c12c1e44ff3a4858bfc89d523daded0e"
          }
        },
        "3532353a7ae246f0a266b42d38cc4901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8555ca1f86bf4ab5bf01e76d8d17ba60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a3f5d1ddcea4cc08ff77ad0b333ea38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c12c1e44ff3a4858bfc89d523daded0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0161ccc141e04aafa1f9a73c39ee0559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51bb77cc6e23422b90131f7df32a0e4a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bd9052aac48471d828192c10abbcd89",
              "IPY_MODEL_776ec8e3b4294baa8e2ae9844e74d99f"
            ]
          }
        },
        "51bb77cc6e23422b90131f7df32a0e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bd9052aac48471d828192c10abbcd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2650f2ddeba746a9b5fb98941d9dd476",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32a0fa2c579942d0b9d939402a4a4dbd"
          }
        },
        "776ec8e3b4294baa8e2ae9844e74d99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2149263e807b4b83b7f84dd14af50b72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:00&lt;00:00, 10.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d63ff6994ff740a991e90f3792738546"
          }
        },
        "2650f2ddeba746a9b5fb98941d9dd476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32a0fa2c579942d0b9d939402a4a4dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2149263e807b4b83b7f84dd14af50b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d63ff6994ff740a991e90f3792738546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4QY_1n681PW",
        "colab_type": "text"
      },
      "source": [
        "## **BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOBGuIPG89SZ",
        "colab_type": "text"
      },
      "source": [
        "BERT (Bidirectional Encoder Representations from Transformer) and its descendants are currently state-of-the-art models for nearly all NLP tasks.\n",
        "\n",
        "Released by Google in 2019, BERT builds powerful context-aware representations of words that can be exploited to perform custom classification tasks.\n",
        "\n",
        "For further details: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQaV4ztz8_9L",
        "colab_type": "text"
      },
      "source": [
        "**Fine-tuning BERT for text classification with Keras and Tensorflow**\n",
        "\n",
        "This notebook fine-tunes BERT for a custom text classification task. Simply, a classification layer is added on top of BERT and the whole model is retrained starting from pre-trained BERT weights.\n",
        "\n",
        "With Keras and Tensorflow, we have all the freedom to customize our classification layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9cZjgczUIvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1.0\n",
        "!pip install tensorflow-gpu \n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFab3shcN4qh",
        "colab_type": "text"
      },
      "source": [
        "**STEP 1**: download pre-trained BERT model.\n",
        "\n",
        "We choose the multilingual model, since the texts we want to classify are in Italian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxdUS6LhUZk9",
        "colab_type": "code",
        "outputId": "15d64ed5-ebf9-4a3d-be05-98cd5f981f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196,
          "referenced_widgets": [
            "bc6fcf7d0a4245c2aa894ee5c387f1b5",
            "b1c5fdbb56844cf2bb99e4efc4f0271e",
            "1376e2d53ef5407c91900730a1ddf379",
            "206d6ed9603f4c61add8cf13c16daabe",
            "81317578f9664e50a9ed74b2e009f26b",
            "b8e26c1c25d24407bbee27cf090bba1d",
            "e23bd30c1a93418889ed0c318f993d05",
            "8ad4a839b38e4b258dce1d039e2a1cf9",
            "b013cfeb128d46c8b601fbcfb7d4d872",
            "1863fbf56e81423cafb200e250f22504",
            "e5133554687241beb4a14ba5a8a48e65",
            "81c681f999c3480cba9383256edd8fa2",
            "3532353a7ae246f0a266b42d38cc4901",
            "8555ca1f86bf4ab5bf01e76d8d17ba60",
            "4a3f5d1ddcea4cc08ff77ad0b333ea38",
            "c12c1e44ff3a4858bfc89d523daded0e",
            "0161ccc141e04aafa1f9a73c39ee0559",
            "51bb77cc6e23422b90131f7df32a0e4a",
            "9bd9052aac48471d828192c10abbcd89",
            "776ec8e3b4294baa8e2ae9844e74d99f",
            "2650f2ddeba746a9b5fb98941d9dd476",
            "32a0fa2c579942d0b9d939402a4a4dbd",
            "2149263e807b4b83b7f84dd14af50b72",
            "d63ff6994ff740a991e90f3792738546"
          ]
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "model_name = 'bert-base-multilingual-cased' # recommended multilingual model (see https://github.com/google-research/bert/blob/master/multilingual.md)\n",
        "\n",
        "print(\"Loading BERT model {}...\".format(model_name))\n",
        "bert_model = TFBertModel.from_pretrained(model_name)    # loads model + pre-trained weights; its layers are Keras layers\n",
        "tokenizer  = BertTokenizer.from_pretrained(model_name)  # to preprocess input sentences\n",
        "print(\"... model loaded successfully.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT model bert-base-multilingual-cased...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc6fcf7d0a4245c2aa894ee5c387f1b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b013cfeb128d46c8b601fbcfb7d4d872",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=1083389348, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0161ccc141e04aafa1f9a73c39ee0559",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "... model loaded successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aG2a2EbOSSz",
        "colab_type": "text"
      },
      "source": [
        "**STEP 2**: load and preprocess data. In this case, we will try to predict an article's topic based on the title.\n",
        "\n",
        "Target classification labels must be one-hot encoded.\n",
        "\n",
        "Input sentences must be *tokenized* (using BERT's tokenizer) and *padded* so that they all have the same length.\n",
        "\n",
        "The padding token is not a proper word and should not be considered when calculating attention weights. Therefore, we declare an attention mask (**padding mask**) that obscures all padding tokens. The padding mask will be passed as an additional input to the BERT layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JWEewokyD8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "df = pd.read_csv(\"articles_topics.csv\")[['title', 'topic']] # about 500 articles\n",
        "\n",
        "# *** Labels\n",
        "\n",
        "labels_dict     = {topic : i for i, topic in enumerate(df.topic.unique())}\n",
        "inv_labels_dict = {i : topic for topic, i in labels_dict.items()}\n",
        "n_labels = len(labels_dict)\n",
        "\n",
        "# one-hot encode the labels: e.g. label = 2 --> encoding = [0, 0, 1, 0, 0, ..., 0] (needed for fine-tuning on classification task)\n",
        "def one_hot_map(label_id, labels_dict = labels_dict, n_labels = n_labels):\n",
        "    label_enc = np.zeros(n_labels)\n",
        "    label_enc[labels_dict[label_id]] = 1.\n",
        "    return label_enc\n",
        "\n",
        "# *** Predictors: convert input texts to a format that can be understood by BERT\n",
        "\n",
        "def texts_to_BERT_input(texts, tokenizer, max_seq_len = None, train_test_split = None):\n",
        "\n",
        "    tokenized_texts = np.array([tokenizer.encode(text) for text in texts])\n",
        "\n",
        "    if max_seq_len is None:\n",
        "        max_seq_len = max(map(len, tokenized_texts))\n",
        "\n",
        "    attention_mask = np.ones((len(tokenized_texts), max_seq_len))\n",
        "    for i in range(len(tokenized_texts)): \n",
        "        seq_len = len(tokenized_texts[i])\n",
        "        n_padding_tokens = max_seq_len - seq_len\n",
        "        tokenized_texts[i] = np.concatenate((tokenized_texts[i], np.zeros(n_padding_tokens))) # pad text to max sequence length (0 = [PAD] token)\n",
        "        attention_mask[i, seq_len:] = 0 # update attention mask (0 = masked input, 1 = input to be used)\n",
        "\n",
        "    input_bert = np.array(list(zip(*(tokenized_texts, attention_mask)))) # input for BERT: tokenized text + attention mask\n",
        "\n",
        "    input_bert = tf.constant(input_bert, dtype = tf.int32)\n",
        "\n",
        "    return input_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN2AuIGM-vWy",
        "colab_type": "text"
      },
      "source": [
        "**STEP 3**: do train-test split (randomly set 80% train and 20% test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wvxsL6mlXUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len = 50 # whatever length should be ok provided it is >= than the maximum tokenized sequence length.\n",
        "                 # Thanks to the attention mask, results should not change if we vary max_seq_len         \n",
        "input_bert = texts_to_BERT_input(df.title.values, tokenizer = tokenizer, max_seq_len = max_seq_len)\n",
        "\n",
        "# Split train / test\n",
        "train_test_split = 0.8\n",
        "n_data  = len(input_bert)\n",
        "n_train = int(train_test_split * n_data)\n",
        "ixs = np.arange(n_data)\n",
        "random.shuffle(ixs)\n",
        "ixs_train, ixs_test = ixs[:n_train], ixs[n_train:]\n",
        "assert len(set(ixs_train).intersection(set(ixs_test))) == 0\n",
        "\n",
        "train_input = tf.constant(input_bert.numpy()[ixs_train, :], dtype = tf.int32)\n",
        "test_input  = tf.constant(input_bert.numpy()[ixs_test , :], dtype = tf.int32)\n",
        "\n",
        "train_labels = tf.constant(np.array([one_hot_map(topic) for topic in df.iloc[ixs_train].topic.values]), dtype = tf.int32)\n",
        "test_labels  = tf.constant(np.array([one_hot_map(topic) for topic in df.iloc[ixs_test] .topic.values]), dtype = tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcvnsgkm_ZBT",
        "colab_type": "text"
      },
      "source": [
        "**STEP 4**: define the model (add classification layer on top of BERT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpqgZZQUI9WU",
        "colab_type": "code",
        "outputId": "ab88e01e-aaa0-4cd2-f525-e803b15baffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "# BERT LAYER\n",
        "input_shape = (input_bert.shape[1], input_bert.shape[2])\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape = input_shape, dtype = 'int32', name = 'input_tokens')  # input: tokenized sentences + attention mask\n",
        "output = bert_model.layers[0](input_layer[:, 0, :], attention_mask = input_layer[:, 1, :])[0]\n",
        "output = tf.keras.layers.Lambda(lambda x : x[:, 0, :], name = 'extract_CLS', output_shape = (None, 768))(output)  # extract representation of [CLS] token\n",
        "\n",
        "# CLASSIFICATION LAYER\n",
        "# added on top of BERT; receives the representation of the [CLS] token as input\n",
        "output = tf.keras.layers.Dropout(0.2, name = 'dropout')(output)\n",
        "output = tf.keras.layers.Dense(n_labels, activation = tf.nn.softmax, name = 'classifier')(output)\n",
        "\n",
        "classifier = tf.keras.Model(inputs = input_layer, outputs = output, name = 'BERT-classifier')\n",
        "\n",
        "classifier.build(input_shape = input_shape)\n",
        "\n",
        "classifier.compile(loss = 'categorical_crossentropy', optimizer = tf.optimizers.Adam(lr = 2E-5), metrics = ['accuracy'])\n",
        "\n",
        "print(classifier.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT-classifier\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_tokens (InputLayer)       [(None, 2, 50)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 50)]         0           input_tokens[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 50)]         0           input_tokens[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          ((None, 50, 768), (N 177853440   tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "extract_CLS (Lambda)            (None, 768)          0           bert[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           extract_CLS[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 11)           8459        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 177,861,899\n",
            "Trainable params: 177,861,899\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpJERb1xqjRW",
        "colab_type": "text"
      },
      "source": [
        "**STEP 5**: train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYyM6QAVLe1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define batch size & batch generator\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "def batch_generator(train_input, train_labels, n_train, batch_size = BATCH_SIZE):\n",
        "    \n",
        "    ixs = np.arange(n_train)\n",
        "    np.random.shuffle(ixs)\n",
        "    \n",
        "    start = 0\n",
        "    while True:\n",
        "        \n",
        "        batch_ixs = ixs[start:start+batch_size]\n",
        "           \n",
        "        start += batch_size\n",
        "        if start > n_train: # end of an epoch\n",
        "            start = 0\n",
        "            np.random.shuffle(ixs)\n",
        "            \n",
        "        yield tf.constant(train_input.numpy()[batch_ixs, :, :], dtype = tf.int32), tf.constant(train_labels.numpy()[batch_ixs], dtype = tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8pJ-2ilMb5n",
        "colab_type": "code",
        "outputId": "d11c44b9-02aa-48e3-d91f-cb138e442b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Do the training\n",
        "\n",
        "n_train = len(train_input)\n",
        "generator = batch_generator(train_input, train_labels, n_train, batch_size = BATCH_SIZE)\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath = 'bert_fine_tuned-{epoch:04d}.ckpt', save_weights_only = True, period = 5, verbose = 1)]\n",
        "\n",
        "classifier.fit_generator(\n",
        "          generator = generator,\n",
        "          epochs    = 20,\n",
        "          steps_per_epoch = int(n_train / BATCH_SIZE) + 1,\n",
        "          validation_data = (test_input, test_labels),\n",
        "          verbose   = 1,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
            "WARNING:tensorflow:From <ipython-input-6-c782638091ba>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 28 steps, validate on 109 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "28/28 [==============================] - 22s 794ms/step - loss: 1.9621 - accuracy: 0.3718 - val_loss: 1.4100 - val_accuracy: 0.5596\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 5s 164ms/step - loss: 1.0469 - accuracy: 0.6697 - val_loss: 0.9342 - val_accuracy: 0.7064\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.5860 - accuracy: 0.8106 - val_loss: 0.9573 - val_accuracy: 0.7523\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.3199 - accuracy: 0.8984 - val_loss: 0.8515 - val_accuracy: 0.7615\n",
            "Epoch 5/20\n",
            "27/28 [===========================>..] - ETA: 0s - loss: 0.1329 - accuracy: 0.9606\n",
            "Epoch 00005: saving model to bert_fine_tuned-0005.ckpt\n",
            "28/28 [==============================] - 27s 976ms/step - loss: 0.1982 - accuracy: 0.9584 - val_loss: 0.9706 - val_accuracy: 0.7431\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 5s 169ms/step - loss: 0.2983 - accuracy: 0.9215 - val_loss: 0.9285 - val_accuracy: 0.7706\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.1046 - accuracy: 0.9700 - val_loss: 0.8593 - val_accuracy: 0.7890\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.0344 - accuracy: 0.9954 - val_loss: 0.8856 - val_accuracy: 0.7523\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.0177 - accuracy: 0.9977 - val_loss: 0.9106 - val_accuracy: 0.7890\n",
            "Epoch 10/20\n",
            "27/28 [===========================>..] - ETA: 0s - loss: 0.0145 - accuracy: 0.9977\n",
            "Epoch 00010: saving model to bert_fine_tuned-0010.ckpt\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.9837 - val_accuracy: 0.7798\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.0219 - accuracy: 0.9977 - val_loss: 0.9345 - val_accuracy: 0.7706\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.0318 - accuracy: 0.9954 - val_loss: 0.9512 - val_accuracy: 0.7798\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 1.0437 - val_accuracy: 0.7615\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0633 - val_accuracy: 0.7615\n",
            "Epoch 15/20\n",
            "27/28 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 00015: saving model to bert_fine_tuned-0015.ckpt\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.7706\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.7798\n",
            "Epoch 17/20\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0953 - val_accuracy: 0.7798\n",
            "Epoch 18/20\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1071 - val_accuracy: 0.7890\n",
            "Epoch 19/20\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.7615\n",
            "Epoch 20/20\n",
            "27/28 [===========================>..] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 00020: saving model to bert_fine_tuned-0020.ckpt\n",
            "28/28 [==============================] - 34s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.7706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5d3148be10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN1nrNsLAD3k",
        "colab_type": "text"
      },
      "source": [
        "You can now load any of your intermediate checkpoints and print out the test set predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91pL06lXO9D0",
        "colab_type": "code",
        "outputId": "154fb906-818e-4012-b4d4-ceb8c0ce3085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "classifier.load_weights('bert_fine_tuned-0020.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5d31481358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJaLqgvdPO4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print test set predictions\n",
        "\n",
        "predictions = classifier.predict(test_input)\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "predictions = [inv_labels_dict[i] for i in predictions]\n",
        "\n",
        "print(\"Test set: {} predictions calculated\".format(len(predictions)))\n",
        "\n",
        "def wrap(text, maxlen = max(map(len, labels_dict.keys()))):\n",
        "    return text+(' ' * (maxlen - len(text)))\n",
        "\n",
        "print(\"{}\\t{}\\t{}\".format(wrap('GROUND TRUTH'), wrap('PREDICTION'), 'TITLE'))\n",
        "for i, ix in enumerate(ixs_test):\n",
        "    print(\"{}\\t{}\\t{}\".format(wrap(df.iloc[ix].topic), wrap(predictions[i]), df.iloc[ix].title))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}