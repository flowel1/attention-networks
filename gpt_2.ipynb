{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI-7wdE21PEx",
        "colab_type": "text"
      },
      "source": [
        "# **GPT-2: an attention-based model for text generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAAs6JaM1SDq",
        "colab_type": "text"
      },
      "source": [
        "gpt-2 (Generative Pre-Training) is an attention-based model by OpenAI specialized in **text generation** tasks. It was released in 2019.\n",
        "\n",
        "For further details: \n",
        "https://openai.com/blog/better-language-models/\n",
        "\n",
        "We will use the model via the Python library gpt-2-simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8IRkfqiHdri",
        "colab_type": "code",
        "outputId": "712d120e-a1a1-4105-f0ff-2bc9ceeef0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciJBoaqT3Gbv",
        "colab_type": "text"
      },
      "source": [
        "## SEE IT IN ACTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKJL_t1B2r8j",
        "colab_type": "text"
      },
      "source": [
        "First, let's download the model and see what it can do!\n",
        "\n",
        "You can also have a look at these:\n",
        "- https://talktotransformer.com/\n",
        "- https://play.aidungeon.io/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBCZ3SLx2QxZ",
        "colab_type": "code",
        "outputId": "7e20648a-4974-47f5-d7b5-67bda82c5c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import gpt_2_simple as gpt2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjTtfRrt2SBR",
        "colab_type": "code",
        "outputId": "41e7e20d-8a36-49f3-e796-a8eb45dc47e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model_name = '124M'   # this is the number of parameters in the model\n",
        "gpt2.download_gpt2(model_name = model_name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 436Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 120Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 370Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:03, 145Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 269Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 174Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 195Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2VWo0bB2cOk",
        "colab_type": "code",
        "outputId": "fcd98d6b-431f-40f6-8232-defcb8692d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "session = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess = session, run_name = model_name, checkpoint_dir = 'models', model_dir = 'models/'+model_name)\n",
        "\n",
        "print(\"\\n\\n*** GENERATED TEXT:\")\n",
        "gpt2.generate(sess        = session,\n",
        "              model_name  = model_name,\n",
        "              temperature = 0.7,\n",
        "              length      = 50,\n",
        "              prefix      = \"I was walking on the street when\") # optional"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "\n",
            "\n",
            "*** GENERATED TEXT:\n",
            "I was walking on the street when I saw this bunch of kids, 25 or 30, and they were talking to my wife and her family. I realized it was so weird. I thought, this is strange.\"\n",
            "\n",
            "The day after the shooting, the family, who were on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jct7IRt21RA",
        "colab_type": "text"
      },
      "source": [
        "## FINE-TUNING\n",
        "\n",
        "gpt-2 can also be **fine-tuned** to learn to generate text of a specific type / genre.\n",
        "\n",
        "We will now teach it to write new Shakespeare plays.\n",
        "\n",
        "First, let's download a dataset of sample Shakespeare works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3aPh3k0H_iL",
        "colab_type": "code",
        "outputId": "a4a0da8d-dc2b-4b16-9266-0881e31f9a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "filename = \"shakespeare.txt\"\n",
        "if not os.path.isfile(filename):\n",
        "    print(\"Dowloading {}\\n\".format(filename))\n",
        "    url  = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "    data = requests.get(url)\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(data.text)\n",
        "\n",
        "with open(filename) as f:\n",
        "    print(f.read()[:500])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dowloading shakespeare.txt\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU8Cf0TO3ozD",
        "colab_type": "text"
      },
      "source": [
        "Now, let's fine-tune!\n",
        "\n",
        "You can do the same with any custom corpus of your choice, provided that the corpus is big enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc_C4iAtM7LU",
        "colab_type": "code",
        "outputId": "e3766b5e-8404-41a1-a121-a2ed34e3a6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "session = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(session,\n",
        "              dataset       = filename,\n",
        "              model_name    = model_name,\n",
        "              steps         = 100,  # just for testing; choose a bigger number like 100\n",
        "              restore_from  = 'fresh',  # change to 'latest' to resume training\n",
        "              run_name      = 'gpt-2-finetuning',\n",
        "              print_every   = 10,   # print loss every ... steps\n",
        "              sample_every  = 20,   # generate sample text every ... steps\n",
        "              sample_length = 300,\n",
        "              save_every    = 500)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 338025 tokens\n",
            "Training...\n",
            "[10 | 18.05] loss=3.71 avg=3.71\n",
            "[20 | 30.54] loss=3.62 avg=3.66\n",
            "======== SAMPLE 1 ========\n",
            "TER_DIMENSION_ALERT (0);\n",
            "\\tvar d = 0, s = 0, n = 0,\n",
            "};\n",
            "\n",
            "\\t}\n",
            "\n",
            "});\n",
            "\n",
            "\\t}\n",
            "\n",
            "};\n",
            "\n",
            "if (this.setTargetSets) {\n",
            "$tw.utils.getObjects(\n",
            "\\\"TargetSets\\\" );\n",
            "\\t} else {\n",
            "this.setTargetSets = true;\n",
            "}\n",
            "};//\n",
            "\n",
            "/**\n",
            "** Clean up all these strings from the DOM:\n",
            "*/\n",
            "function cleanUpString(text):\n",
            "return\n",
            "this.replace(text,\n",
            "\\\"\\\");\n",
            "};\n",
            "const tiddlerClassName = \\\"test\\\", $tw.config.vendor.test.Classes;\n",
            "var text = this.contains(\"test.txt\", null, 'test.txt':0, 'test.txt:test.txt');\n",
            "var text = this.contains(\"test.txt\", \\\"test.txt'', 'test.txt');\n",
            "var text = this.contains(\"test.txt\", \\\"test.','.'');\n",
            "var text = this.contains(\"test.txt\", \\\"test.',\n",
            "'test of test.txt.'';\n",
            "var text = this.removeClass(\"test.txt');\n",
            "\n",
            "var text = this.removeClass(\"test.txt\");\n",
            "var text = this.removeClass(\"test.txt\");\n",
            "var text\n",
            "\n",
            "[30 | 46.82] loss=3.43 avg=3.58\n",
            "[40 | 59.34] loss=3.51 avg=3.56\n",
            "======== SAMPLE 1 ========\n",
            " a\n",
            "'Fascit das het, o'er, and o'er;\n",
            "It is, or rather, or rather, in our favour;\n",
            "A man that 'tis, let me make thee thy\n",
            "part for the best. 'Tis it no great honour, 'tis it, o'er, for 'tis but the fairest\n",
            "women to live?\n",
            "\n",
            "KING JESSICA:\n",
            "We, as well as I, are 'tware your daughts, for 'tis some men more, they give a\n",
            "wonderful service, and are often so\n",
            "wonderful to all.\n",
            "\n",
            "INNISIO:\n",
            "It was no noble deed so great a good,\n",
            "For this day that I had a good feast.\n",
            "\n",
            "KING JESSINA:\n",
            "Why 'tis so? for in all times we are so\n",
            "better! we are a much better company.\n",
            "\n",
            "INNISIO:\n",
            "'Tis not, o'er, for the best; not for 'tis such a good\n",
            "as so in any company.\n",
            "\n",
            "KING JESSINA:\n",
            "Why, O, why, 'tis so.\n",
            "\n",
            "INNISIO:\n",
            "\n",
            "KING JESSINA:\n",
            "And why, O, why, did I not make 'em a\n",
            "good party?\n",
            "\n",
            "KING JESSINA:\n",
            "O, I did not say so, sir! It took me\n",
            "to this party\n",
            "\n",
            "[50 | 74.43] loss=3.44 avg=3.54\n",
            "[60 | 86.95] loss=3.32 avg=3.50\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "\n",
            "Away from the king, I fear it were not you.\n",
            "I have heard no word of him;\n",
            "But there must be a prince to make the king's word:\n",
            "The king himself has come and you know,\n",
            "A wise and noble old man is on his way.\n",
            "I pray you, come to this place.\n",
            "The king is gone: hence comes our waymen:\n",
            "If you must fight and die you must quit your horse\n",
            "As he stands, so he can be made to quit his\n",
            "horse.\n",
            "\n",
            "KING HENRY VI\n",
            "\n",
            "BIDENSLAND\n",
            "\n",
            "\n",
            "\n",
            "RIVERSIDE:\n",
            "\n",
            "KING HENRY VI\n",
            "\n",
            "NORTHAM\n",
            "\n",
            "RIVERSELON:\n",
            "God bless you, the Duke of York\n",
            "As if he were King Edward.\n",
            "\n",
            "JOHN KING HENRY VI\n",
            "\n",
            "AUGUSTINE:\n",
            "I have seen the prince's son\n",
            "Sometime more than one thousand years, and I was\n",
            "furious with him: but, 'tis him who said:\n",
            "If you should be a nobleman thou must be\n",
            "a valiant knight, a true master in arms,\n",
            "A king of the kingdom; and if your father\n",
            "A poor or unkind one, thou shall be like a noble knight.\n",
            "\n",
            "PETRUCHIO:\n",
            "Ay, ay, 'tis true: but now that you are grown of it\n",
            "it is hard in Rome: where's it\n",
            "\n",
            "[70 | 102.05] loss=3.25 avg=3.47\n",
            "[80 | 114.56] loss=2.93 avg=3.40\n",
            "======== SAMPLE 1 ========\n",
            " have be so kind and loving!\n",
            "\n",
            "GLOUCESTER:\n",
            "I have a friend as worthy of God,\n",
            "Which I have not seen; but I think so,\n",
            "That with all the rest must he love it,\n",
            "Which so shall know the time when it grows\n",
            "To see; for I have a friend.\n",
            "\n",
            "MORTY:\n",
            "Do you remember? I was once a child\n",
            "On the field which we have now a mile:\n",
            "In the middle of it lay a soldier whose blood\n",
            "Is boiling, and on the base and the crest\n",
            "Of some great war, some glorious monument;\n",
            "So to my knee to my lip, and my head\n",
            "To my forehead; and there are other places\n",
            "Where soldiers are, so to speak, not so little soldiers.\n",
            "\n",
            "GROWING:\n",
            "Here's another old man with eyes:\n",
            "He's come to our house; but now he sees\n",
            "Some man, a good fellow by the name, sitting about\n",
            "There, like a bear.\n",
            "\n",
            "BUCKING:\n",
            "We have not a man else's eyes; yet he does\n",
            "Have a good one; so you must think, that we\n",
            "Must be honest.\n",
            "\n",
            "MORTY:\n",
            "What's your opinion on the matter?\n",
            "\n",
            "BUCKING:\n",
            "That a thing of this kind\n",
            "Is too much for his self, and too much for him.\n",
            "I mean to say this with some degree of truth;\n",
            "\n",
            "[90 | 129.69] loss=3.48 avg=3.41\n",
            "[100 | 142.17] loss=3.21 avg=3.38\n",
            "Saving checkpoint/gpt-2-finetuning/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}